{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ea4305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-B661AT2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>covid</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=covid>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"covid\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b25a24db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_region : string (nullable = true)\n",
      " |-- confirmed: integer (nullable = true)\n",
      " |-- deaths : integer (nullable = true)\n",
      " |-- recovered: integer (nullable = true)\n",
      " |-- actived: integer (nullable = true)\n",
      " |-- new_cases: integer (nullable = true)\n",
      " |-- new_deaths : integer (nullable = true)\n",
      " |-- new_recovered: integer (nullable = true)\n",
      " |-- deaths100cases : double (nullable = true)\n",
      " |-- recoverded100cases : double (nullable = true)\n",
      " |-- deaths100recovered : double (nullable = true)\n",
      " |-- confirmedlastweek : integer (nullable = true)\n",
      " |-- 1weekchange : integer (nullable = true)\n",
      " |-- 1weekperincrease : double (nullable = true)\n",
      " |-- who_region : string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- province_state : string (nullable = true)\n",
      " |-- country_region : string (nullable = true)\n",
      " |-- Lat : double (nullable = true)\n",
      " |-- Long : double (nullable = true)\n",
      " |-- date : date (nullable = true)\n",
      " |-- confirmed : integer (nullable = true)\n",
      " |-- deaths : integer (nullable = true)\n",
      " |-- recovered : integer (nullable = true)\n",
      " |-- actived : integer (nullable = true)\n",
      " |-- whor_region : string (nullable = true)\n",
      "\n",
      "+--------------------+-------------------+--------+---------+----------+----------+-------+----------+--------+--------------------+\n",
      "|     province_state |    country_region |    Lat |    Long |     date |confirmed |deaths |recovered |actived |        whor_region |\n",
      "+--------------------+-------------------+--------+---------+----------+----------+-------+----------+--------+--------------------+\n",
      "|                    |        Afghanistan|33.93911|67.709953|2020-01-22|         0|      0|         0|       0|Eastern Mediterra...|\n",
      "|                    |            Albania| 41.1533|  20.1683|2020-01-22|         0|      0|         0|       0|              Europe|\n",
      "|                    |            Algeria| 28.0339|   1.6596|2020-01-22|         0|      0|         0|       0|              Africa|\n",
      "|                    |            Andorra| 42.5063|   1.5218|2020-01-22|         0|      0|         0|       0|              Europe|\n",
      "|                    |             Angola|-11.2027|  17.8739|2020-01-22|         0|      0|         0|       0|              Africa|\n",
      "|                    |Antigua and Barbuda| 17.0608| -61.7964|2020-01-22|         0|      0|         0|       0|            Americas|\n",
      "|                    |          Argentina|-38.4161| -63.6167|2020-01-22|         0|      0|         0|       0|            Americas|\n",
      "|                    |            Armenia| 40.0691|  45.0382|2020-01-22|         0|      0|         0|       0|              Europe|\n",
      "|Australian Capita...|          Australia|-35.4735| 149.0124|2020-01-22|         0|      0|         0|       0|     Western Pacific|\n",
      "|     New South Wales|          Australia|-33.8688| 151.2093|2020-01-22|         0|      0|         0|       0|     Western Pacific|\n",
      "+--------------------+-------------------+--------+---------+----------+----------+-------+----------+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "[['date ', 'date'], ['confirmed ', 'int'], ['deaths ', 'int'], ['recovered ', 'int'], ['actived ', 'int'], ['new_cases', 'int'], ['new_deaths ', 'int'], ['new_recovered', 'int'], ['deaths100cases ', 'double'], ['recoverded100cases ', 'double'], ['deaths100recoverded ', 'double'], ['numcountries', 'int']]\n",
      "['2020-01-22,555,17,28,510,0,0,0,3.06,5.05,60.71,6', '2020-01-23,654,18,30,606,99,1,2,2.75,4.59,60.0,8', '2020-01-24,941,26,36,879,287,8,6,2.76,3.83,72.22,9', '2020-01-25,1434,42,39,1353,493,16,3,2.93,2.72,107.69,11']\n",
      "root\n",
      " |-- date : date (nullable = true)\n",
      " |-- confirmed : integer (nullable = true)\n",
      " |-- deaths : integer (nullable = true)\n",
      " |-- recovered : integer (nullable = true)\n",
      " |-- actived : integer (nullable = true)\n",
      " |-- new_cases: integer (nullable = true)\n",
      " |-- new_deaths : integer (nullable = true)\n",
      " |-- new_recovered: integer (nullable = true)\n",
      " |-- deaths100cases : double (nullable = true)\n",
      " |-- recoverded100cases : double (nullable = true)\n",
      " |-- deaths100recoverded : double (nullable = true)\n",
      " |-- numcountries: integer (nullable = true)\n",
      "\n",
      "+----------+----------+-------+----------+--------+---------+-----------+-------------+---------------+-------------------+--------------------+------------+\n",
      "|     date |confirmed |deaths |recovered |actived |new_cases|new_deaths |new_recovered|deaths100cases |recoverded100cases |deaths100recoverded |numcountries|\n",
      "+----------+----------+-------+----------+--------+---------+-----------+-------------+---------------+-------------------+--------------------+------------+\n",
      "|2020-01-22|       555|     17|        28|     510|        0|          0|            0|           3.06|               5.05|               60.71|           6|\n",
      "|2020-01-23|       654|     18|        30|     606|       99|          1|            2|           2.75|               4.59|                60.0|           8|\n",
      "|2020-01-24|       941|     26|        36|     879|      287|          8|            6|           2.76|               3.83|               72.22|           9|\n",
      "|2020-01-25|      1434|     42|        39|    1353|      493|         16|            3|           2.93|               2.72|              107.69|          11|\n",
      "|2020-01-26|      2118|     56|        52|    2010|      684|         14|           13|           2.64|               2.46|              107.69|          13|\n",
      "|2020-01-27|      2927|     82|        61|    2784|      809|         26|            9|            2.8|               2.08|              134.43|          16|\n",
      "|2020-01-28|      5578|    131|       107|    5340|     2651|         49|           46|           2.35|               1.92|              122.43|          16|\n",
      "|2020-01-29|      6166|    133|       125|    5908|      588|          2|           18|           2.16|               2.03|               106.4|          18|\n",
      "|2020-01-30|      8234|    171|       141|    7922|     2068|         38|           16|           2.08|               1.71|              121.28|          20|\n",
      "|2020-01-31|      9927|    213|       219|    9495|     1693|         42|           78|           2.15|               2.21|               97.26|          24|\n",
      "+----------+----------+-------+----------+--------+---------+-----------+-------------+---------------+-------------------+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- country_region : string (nullable = true)\n",
      " |-- confirmed: integer (nullable = true)\n",
      " |-- recovered: integer (nullable = true)\n",
      " |-- actived: integer (nullable = true)\n",
      " |-- new_cases: integer (nullable = true)\n",
      " |-- new_deaths : integer (nullable = true)\n",
      " |-- new_recovered: integer (nullable = true)\n",
      " |-- who_region: string (nullable = true)\n",
      "\n",
      "+----------+-------------------+---------+---------+-------+---------+-----------+-------------+----------+\n",
      "|      date|    country_region |confirmed|recovered|actived|new_cases|new_deaths |new_recovered|who_region|\n",
      "+----------+-------------------+---------+---------+-------+---------+-----------+-------------+----------+\n",
      "|2020-01-22|        Afghanistan|        0|        0|      0|        0|          0|            0|         0|\n",
      "|2020-01-22|            Albania|        0|        0|      0|        0|          0|            0|         0|\n",
      "|2020-01-22|            Algeria|        0|        0|      0|        0|          0|            0|         0|\n",
      "|2020-01-22|            Andorra|        0|        0|      0|        0|          0|            0|         0|\n",
      "|2020-01-22|             Angola|        0|        0|      0|        0|          0|            0|         0|\n",
      "|2020-01-22|Antigua and Barbuda|        0|        0|      0|        0|          0|            0|         0|\n",
      "|2020-01-22|          Argentina|        0|        0|      0|        0|          0|            0|         0|\n",
      "|2020-01-22|            Armenia|        0|        0|      0|        0|          0|            0|         0|\n",
      "|2020-01-22|          Australia|        0|        0|      0|        0|          0|            0|         0|\n",
      "|2020-01-22|            Austria|        0|        0|      0|        0|          0|            0|         0|\n",
      "+----------+-------------------+---------+---------+-------+---------+-----------+-------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_region : string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- population: integer (nullable = true)\n",
      " |-- totalases: integer (nullable = true)\n",
      " |-- newcases: integer (nullable = true)\n",
      " |-- totaldeaths: integer (nullable = true)\n",
      " |-- newdeaths: integer (nullable = true)\n",
      " |-- totalrecovered: integer (nullable = true)\n",
      " |-- newrecovered: integer (nullable = true)\n",
      " |-- activecases: integer (nullable = true)\n",
      " |-- serious_critical: integer (nullable = true)\n",
      " |-- totcases1Mpop: integer (nullable = true)\n",
      " |-- deaths1Mpop: integer (nullable = true)\n",
      " |-- totaltests: integer (nullable = true)\n",
      " |-- tests1Mpop: integer (nullable = true)\n",
      " |-- who_region : string (nullable = true)\n",
      "\n",
      "+---------------+-------------+----------+---------+--------+-----------+---------+--------------+------------+-----------+----------------+-------------+-----------+----------+----------+--------------+\n",
      "|country_region |    continent|population|totalases|newcases|totaldeaths|newdeaths|totalrecovered|newrecovered|activecases|serious_critical|totcases1Mpop|deaths1Mpop|totaltests|tests1Mpop|   who_region |\n",
      "+---------------+-------------+----------+---------+--------+-----------+---------+--------------+------------+-----------+----------------+-------------+-----------+----------+----------+--------------+\n",
      "|            USA|North America| 331198130|  5032179|       0|     162804|        0|       2576668|           0|    2292707|           18296|        15194|        492|  63139605|    190640|      Americas|\n",
      "|         Brazil|South America| 212710692|  2917562|       0|      98644|        0|       2047660|           0|     771258|            8318|        13716|        464|  13206188|     62085|      Americas|\n",
      "|          India|         Asia|1381344997|  2025409|       0|      41638|        0|       1377384|           0|     606387|            8944|         1466|         30|  22149351|     16035|South-EastAsia|\n",
      "|         Russia|       Europe| 145940924|   871894|       0|      14606|        0|        676357|           0|     180931|            2300|         5974|        100|  29716907|    203623|        Europe|\n",
      "|   South Africa|       Africa|  59381566|   538184|       0|       9604|        0|        387316|           0|     141264|             539|         9063|        162|   3149807|     53044|        Africa|\n",
      "|         Mexico|North America| 129066160|   462690|    6590|      50517|      819|        308848|        4140|     103325|            3987|         3585|        391|   1056915|      8189|      Americas|\n",
      "|           Peru|South America|  33016319|   455409|       0|      20424|        0|        310337|           0|     124648|            1426|        13793|        619|   2493429|     75521|      Americas|\n",
      "|          Chile|South America|  19132514|   366671|       0|       9889|        0|        340168|           0|      16614|            1358|        19165|        517|   1760615|     92022|      Americas|\n",
      "|       Colombia|South America|  50936262|   357710|       0|      11939|        0|        192355|           0|     153416|            1493|         7023|        234|   1801835|     35374|      Americas|\n",
      "|          Spain|       Europe|  46756648|   354530|       0|      28500|        0|             0|           0|          0|             617|         7582|        610|   7064329|    151087|        Europe|\n",
      "+---------------+-------------+----------+---------+--------+-----------+---------+--------------+------------+-----------+----------------+-------------+-----------+----------+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- uid: integer (nullable = true)\n",
      " |-- iso2 : string (nullable = true)\n",
      " |-- iso3: string (nullable = true)\n",
      " |-- code3: integer (nullable = true)\n",
      " |-- fips: double (nullable = true)\n",
      " |-- admin2: string (nullable = true)\n",
      " |-- province_state : string (nullable = true)\n",
      " |-- country_region: string (nullable = true)\n",
      " |-- lat : double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- confirmed : integer (nullable = true)\n",
      " |-- deaths : integer (nullable = true)\n",
      "\n",
      "+--------+-----+----+-----+-------+------------+--------------------+--------------+---------+----------+----------+----------+-------+\n",
      "|     uid|iso2 |iso3|code3|   fips|      admin2|     province_state |country_region|     lat |      long|      date|confirmed |deaths |\n",
      "+--------+-----+----+-----+-------+------------+--------------------+--------------+---------+----------+----------+----------+-------+\n",
      "|      16|   AS| ASM|   16|   60.0|            |      American Samoa|            US|  -14.271|  -170.132|2020-01-22|         0|      0|\n",
      "|     316|   GU| GUM|  316|   66.0|            |                Guam|            US|  13.4443|  144.7937|2020-01-22|         0|      0|\n",
      "|     580|   MP| MNP|  580|   69.0|            |Northern Mariana ...|            US|  15.0979|  145.6739|2020-01-22|         0|      0|\n",
      "|63072001|   PR| PRI|  630|72001.0|    Adjuntas|         Puerto Rico|            US|18.180117|-66.754367|2020-01-22|         0|      0|\n",
      "|63072003|   PR| PRI|  630|72003.0|      Aguada|         Puerto Rico|            US|18.360255|-67.175131|2020-01-22|         0|      0|\n",
      "|63072005|   PR| PRI|  630|72005.0|   Aguadilla|         Puerto Rico|            US|18.459681|-67.120815|2020-01-22|         0|      0|\n",
      "|63072007|   PR| PRI|  630|72007.0|Aguas Buenas|         Puerto Rico|            US|18.251619|-66.126806|2020-01-22|         0|      0|\n",
      "|63072009|   PR| PRI|  630|72009.0|    Aibonito|         Puerto Rico|            US|18.131361|-66.264131|2020-01-22|         0|      0|\n",
      "|63072011|   PR| PRI|  630|72011.0|      Anasco|         Puerto Rico|            US|18.287985|-67.120611|2020-01-22|         0|      0|\n",
      "|63072013|   PR| PRI|  630|72013.0|     Arecibo|         Puerto Rico|            US|18.406631|-66.675077|2020-01-22|         0|      0|\n",
      "+--------+-----+----+-----+-------+------------+--------------------+--------------+---------+----------+----------+----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, DoubleType, StringType,DateType\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from datetime import datetime\n",
    "import csv\n",
    "def get_header(filename):\n",
    "    headers = sc.textFile(filename).map(lambda line: line.split(\":\")).collect()\n",
    "    return headers\n",
    "def read_csv(filename):\n",
    "    textFileRecordsRDD = sc.textFile(filename)\n",
    "    header = textFileRecordsRDD.first()\n",
    "    textFileRecordsRDD = textFileRecordsRDD.filter(lambda row: row != header)\n",
    "    # Toma los primeros 4 registros (excluyendo la cabecera)\n",
    "    \n",
    "    resultados = textFileRecordsRDD.take(4)\n",
    "    #print(type(textFileRecordsRDD))  \n",
    "    return  textFileRecordsRDD\n",
    "def strToType(str):\n",
    "  if str == 'int':\n",
    "    return IntegerType()\n",
    "  elif str == 'double':\n",
    "    return DoubleType()\n",
    "  elif str == 'date':\n",
    "    return DateType()\n",
    "  else:\n",
    "    return StringType()\n",
    "def parseLine(line, headers):\n",
    "    tokens = zip(line.split(\",\"), headers)\n",
    "    parsed_tokens = []\n",
    "    for token, header in tokens:\n",
    "        token_type = header[1]\n",
    "        print('token_type = ', token_type)\n",
    "        if token_type == 'double':\n",
    "            parsed_tokens.append(float(token))\n",
    "        elif token_type == 'int':\n",
    "            parsed_value = int(token) if token != '' else 0\n",
    "            parsed_tokens.append(parsed_value)\n",
    "        elif token_type == 'date':\n",
    "            try:\n",
    "                date_obj = datetime.strptime(token, '%Y-%m-%d').date()\n",
    "            except ValueError:\n",
    "                date_obj = datetime.strptime(token, '%m/%d/%y').date()\n",
    "            parsed_tokens.append(date_obj)\n",
    "        else:\n",
    "            parsed_tokens.append(token)\n",
    "\n",
    "    return parsed_tokens    \n",
    "    \n",
    "#carga del country_wise_latest\n",
    "head_wise =get_header('country_wise_latest.txt') \n",
    "country_wiser_rdd =read_csv('country_wise_latest.csv')\n",
    "#records = country_wiser_rdd.map(parseLine)\n",
    "records = country_wiser_rdd.map(lambda line: parseLine(line, head_wise))\n",
    "schema_wise = StructType(\n",
    "    [StructField(t[0], strToType(t[1]), True) for t in head_wise]\n",
    ")\n",
    "# df = sc.createDataFrame(records, schema)\n",
    "df_country_wiser = spark.createDataFrame(records, schema_wise)\n",
    "# Muestra al menos una línea de datos del DataFrame utilizando el método 'take'\n",
    "#data = df_country_wiser.take(1)\n",
    "df_country_wiser.printSchema()\n",
    "#-------------------------------------\n",
    "#carga del covid_19_clean_complete\n",
    "head_clean =get_header('covid_19_clean_complete.txt') \n",
    "#print(head_clean)\n",
    "country_wiser_rdd =read_csv('covid_19_clean_complete.csv')\n",
    "#print(country_wiser_rdd.take(4))\n",
    "#records = country_wiser_rdd.map(parseLine)\n",
    "records = country_wiser_rdd.map(lambda line: parseLine(line, head_clean))\n",
    "schema_clean = StructType(\n",
    "    [StructField(t[0], strToType(t[1]), True) for t in head_clean]\n",
    ")\n",
    "# df = sc.createDataFrame(records, schema)\n",
    "df_covid_19_clean_complete = spark.createDataFrame(records, schema_clean)\n",
    "# Muestra al menos una línea de datos del DataFrame utilizando el método 'take'\n",
    "df_covid_19_clean_complete.printSchema()\n",
    "df_covid_19_clean_complete.show(10)\n",
    "\n",
    "#-------------------------------------\n",
    "#carga del day_wise\n",
    "head_day_wise =get_header('day_wise.txt') \n",
    "print(head_day_wise)\n",
    "country_wiser_rdd =read_csv('day_wise.csv')\n",
    "print(country_wiser_rdd.take(4))\n",
    "#records = country_wiser_rdd.map(parseLine)\n",
    "records = country_wiser_rdd.map(lambda line: parseLine(line, head_day_wise))\n",
    "schema_day_wise = StructType(\n",
    "    [StructField(t[0], strToType(t[1]), True) for t in head_day_wise]\n",
    ")\n",
    "# df = sc.createDataFrame(records, schema)\n",
    "df_day_wise = spark.createDataFrame(records, schema_day_wise)\n",
    "# Muestra al menos una línea de datos del DataFrame utilizando el método 'take'\n",
    "df_day_wise.printSchema()\n",
    "df_day_wise.show(10)\n",
    "\n",
    "\n",
    "#-------------------------------------\n",
    "#carga del full_grouped\n",
    "head_full_grouped =get_header('full_grouped.txt') \n",
    "#print(head_full_grouped)\n",
    "full_grouped_rdd =read_csv('full_grouped.csv')\n",
    "#print(full_grouped_rdd.take(4))\n",
    "#records = country_wiser_rdd.map(parseLine)\n",
    "records = full_grouped_rdd.map(lambda line: parseLine(line, head_full_grouped))\n",
    "schema_full_grouped = StructType(\n",
    "    [StructField(t[0], strToType(t[1]), True) for t in head_full_grouped]\n",
    ")\n",
    "# df = sc.createDataFrame(records, schema)\n",
    "df_schema_full_grouped = spark.createDataFrame(records, schema_full_grouped)\n",
    "# Muestra al menos una línea de datos del DataFrame utilizando el método 'take'\n",
    "df_schema_full_grouped.printSchema()\n",
    "df_schema_full_grouped.show(10)\n",
    "\n",
    "#-------------------------------------\n",
    "#carga del worldometer_data\n",
    "head_worldometer_data =get_header('worldometer_data.txt') \n",
    "#print(head_full_grouped)\n",
    "worldometer_data_rdd =read_csv('worldometer_data.csv')\n",
    "#print(full_grouped_rdd.take(4))\n",
    "#records = country_wiser_rdd.map(parseLine)\n",
    "records = worldometer_data_rdd.map(lambda line: parseLine(line, head_worldometer_data))\n",
    "schema_worldometer_data = StructType(\n",
    "    [StructField(t[0], strToType(t[1]), True) for t in head_worldometer_data]\n",
    ")\n",
    "# df = sc.createDataFrame(records, schema)\n",
    "df_schema_worldometer_data = spark.createDataFrame(records, schema_worldometer_data)\n",
    "# Muestra al menos una línea de datos del DataFrame utilizando el método 'take'\n",
    "df_schema_worldometer_data.printSchema()\n",
    "df_schema_worldometer_data.show(10)\n",
    "\n",
    "\n",
    "#-------------------------------------\n",
    "#carga del head_usa_county_wise\n",
    "head_usa_county_wise =get_header('usa_county_wise.txt') \n",
    "#print(head_full_grouped)\n",
    "usa_county_wise_rdd =read_csv('usa_county_wise.csv')\n",
    "#print(full_grouped_rdd.take(4))\n",
    "#records = country_wiser_rdd.map(parseLine)\n",
    "records = usa_county_wise_rdd.map(lambda line: parseLine(line, head_usa_county_wise))\n",
    "schema_usa_county_wise = StructType(\n",
    "    [StructField(t[0], strToType(t[1]), True) for t in head_usa_county_wise]\n",
    ")\n",
    "# df = sc.createDataFrame(records, schema)\n",
    "df_schema_usa_county_wise = spark.createDataFrame(records, schema_usa_county_wise)\n",
    "# Muestra al menos una línea de datos del DataFrame utilizando el método 'take'\n",
    "df_schema_usa_county_wise.printSchema()\n",
    "df_schema_usa_county_wise.show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c7c150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
